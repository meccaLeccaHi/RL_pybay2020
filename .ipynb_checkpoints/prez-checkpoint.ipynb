{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hi\n",
    "- I'm Adam.\n",
    "    - Super brief bio\n",
    "        - Links\n",
    "    - Numerous RL projects in the past.\n",
    "        - Included in my public repositories on GH."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"overview\"></a>\n",
    "\n",
    "Everyone in this room can be conceptualized as a series of records that have, do, or will exist.\n",
    "- We begin with a birth certificate ...\n",
    "- ... and end with a death certificate.\n",
    "- In between, there will be medical records, school records, marriage records, bank records, arrest records, etc.\n",
    "\n",
    "Imagine what we could learn about ourselves by integrating all of that information, from all of those different sources, into one single, cohesive story."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And, if data were perfectly clean, this would be a simple `JOIN` operation.\n",
    "- <b>But it's not.</b> Which is why we need techniques to integrate inconsistent data.\n",
    "- Those techniques will be the focus of this talk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quick example\n",
    "\n",
    "- Public health example: Joining hospital records to birth certificates.\n",
    "    - What problems would occur?\n",
    "        1. People change\n",
    "            - Names, addresses, ...\n",
    "        2. People make mistakes\n",
    "            - Typos, spelling errors, nicknames, abbreviations, ...\n",
    "        3. People lie\n",
    "            - Age, weight, neighborhood, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"areas\"></a>\n",
    "## Application areas\n",
    "Data matching is not new -- well before computers, we needed to match records belonging to the same individual.\n",
    "- National census\n",
    "    - Governments around the world rely on census data to allocate resources appropriately.\n",
    "    - RL plays an important role in improving the quality and accuracy of census data.\n",
    "    - The U.S. Census Bureau has played a major role in the development of RL techniques for several decades.\n",
    "\n",
    "<p><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/85/Seal_of_the_United_States_Census_Bureau.svg/200px-Seal_of_the_United_States_Census_Bureau.svg.png\" alt=\"Census Bureau seal\" height=\"140\" width=\"140\">    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Medicine and public health \n",
    "    - (historically referred to as _medical_ record linkage)\n",
    "    - Simply consider all of the doctors, hospitals, insurance companies, and pharmacies you've interacted with and it becomes obvious why medical records are another major RL application area.\n",
    "    - In addition, _longitudinally-matched records_ can provide novel insights into health outcomes, as in the example given previously.\n",
    "    \n",
    "<p><img width=\"256\" alt=\"Seattle physician with patient 1999\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/45/Seattle_physician_with_patient_1999.jpg/256px-Seattle_physician_with_patient_1999.jpg\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Customer records\n",
    "    - In order to effectively target their customers, businesses need to minimize the redundancy that tends to occur as a result of changes in name, address, etc.\n",
    "    - This requires businesses to periodically remove redundant records, in order to maintain an accurate record of their customer base (often a main source of revenue) and reach those customers effectively.\n",
    "    \n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/en/7/78/DB-database-icon.png\" alt=\"DB-database-icon.png\" width=\"200\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Genealogy\n",
    "    - Given that more than 10% of men and women were named 'John' and 'Mary' in nineteenth century England, it becomes obvious why RL is an invaluable tool for genealogical databases, some of which are now a billion-dollar industry.\n",
    "    - [LDS have spent a lot of $$$ and published a few papers on RL]\n",
    "    \n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/a/a8/1900_census_Kershaw_Lindauer.gif\" alt=\"1900 census Kershaw Lindauer.gif\" height=\"480\" width=\"456\">\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align: right\">1900 US Census, Public Domain, <a href=\"https://commons.wikimedia.org/w/index.php?curid=11768459\">Link</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"why\"></a>\n",
    "## Why do I care?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- As a society, we are producing more data than ever before. In order to make use of it, we need intelligent solutions to integrate data from disparate sources.\n",
    "- Such tools play an important role in both data mining _and_ data warehousing -- using RL, we can not only improve the quality (and statistical power) of our data, but also reveal relationships not contained within any single database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# [Overview](#overview)\n",
    "\n",
    "## [Quick example](#example)\n",
    "\n",
    "## [Application areas](#areas)\n",
    "\n",
    "## [Why do I care?](#why)\n",
    "\n",
    "# [Challenges](#challenges)\n",
    "- First, I want to make you aware of the specific, unique challenges involved with RL, so you can better appreciate why the approach includes the steps it does.\n",
    "\n",
    "## [Missing unique identifiers](#unique)\n",
    "- Records on people or businesses is often very 'messy' with inconsistent formatting from one database to the next.\n",
    "- This makes finding unique matches unlikely. Instead, for each record there is a handful of plausible matches, each matching to a varying degree.\n",
    "    \n",
    "## [Computational complexity](#complexity)\n",
    "- Because any time you're working with Cartesian products you are working with a quadratic time complexity ($0(n^2)$), intelligent sub-setting of your data (via 'blocking') becomes essential.\n",
    "\n",
    "## [Lack of training labels](#labels)\n",
    "- Due to the expense of hand-labeling training data, we often need to use an unsupervised approach to RL.\n",
    "\n",
    "## [Privacy](#privacy)\n",
    "- In spite of our attempts to keep nice, complete databases, people still demand privacy (go figure).\n",
    "- As a result, fields that include identifying information are often removed or encrypted, adding to the challenge of our task.\n",
    "    \n",
    "\n",
    "# [Classic record linkage](#classic)\n",
    "- Second, I want to give you a snapshot of the classic record linkage approach which will include:\n",
    "\n",
    "## [Pre-processing](#pre)\n",
    "- Normalization of undesired variation\n",
    "- Ensuring consistent formatting\n",
    "\n",
    "## [Indexing (blocking)](#blocking)\n",
    "- To reduce the complexity of the task by beginning with smaller subsets of data that are very likely to contain matching records.\n",
    "\n",
    "## [Comparison and classification](#classification)\n",
    "- Classification of each record pair into 'matches' and 'non-matches' can be performed using either a deterministic (rule-based) or probabilistic (model-based) approach.\n",
    "- In the probabilistic approach, comparisons between pairs are broken down into feature vectors summarizing their agreement along multiple dimensions, both simple (e.g. name, address, D.O.B.) and complex (e.g. distance between addresses).\n",
    "- With those feature vectors, we can apply any one of hundreds of different classification models to attempt to predict whether those records are 'matches' or not.\n",
    "\n",
    "## [Evaluation](#evaluation)\n",
    "- Evaluation involves determining how successful the linkage was, in terms of correctly identified pairs.\n",
    "- This can be complicated by the class imbalance between 'match' vs 'non-match' samples.\n",
    "\n",
    "# [Demo](#demo)\n",
    "\n",
    "## [Comparing the performance of classifiers](#comparing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"challenges\"></a>\n",
    "# Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<a id=\"unique\"></a>\n",
    "## Missing unique identifiers\n",
    "\n",
    "In all of these cases, the challenge that we have to overcome is missing a unique identifier for the entities we are matching.\n",
    "- For example, if we had perfectly accurate social security numbers for each record, the task is reduced to a straight-forward join of two databases.\n",
    "- This is often not the case for multiple reasons:\n",
    "    1. accurate record keeping is hard\n",
    "    2. privacy is usually a concern (in some countries use of such identifiers is illegal).\n",
    "- As such, in order to match records across databases, we must use common attributes shared by both databases.\n",
    "    - e.g. Name, address, phone number, age\n",
    "- The quality of data points such as these are notoriously low for reasons described earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<a id=\"complexity\"></a>\n",
    "## Computational complexity\n",
    "- As a naive approach, one might try comparing each record in one database, to each record in the other, to determine if each pair under consideration might be a match.\n",
    "- The computational complexity of such an approach, however, grows quadratically ($O(NÂ²)$) with the size of the smaller database.\n",
    "- As we'll see, some nice tricks exist to reduce the size of the problem substantially."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<a id=\"labels\"></a>\n",
    "## Lack of training labels\n",
    "- In the typical (supervised) machine learning approach, labeled training data is used as feedback by a statistical model during the process of training. \n",
    "- In some cases, the there is no training data that tells us if two records correspond to the same individual or not.\n",
    "- This can make the evaluation of the model's matches especially challenging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<a id=\"privacy\"></a>\n",
    "## Privacy\n",
    "- Given that these records often contain sensitive personal information (such as medical/employment records), special attention must be paid to preserving this privacy via _'de-identification'_.\n",
    "- This is especially important for academic or medical researchers using HIPAA-protected datasets for research use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"classic\"></a>\n",
    "# Classic record linkage\n",
    "I will use 'record linkage' to refer to both the matching of records across two (or more) databases.\n",
    "- This can also include the special case of _'de-duplication'_, which simply involves using the same approach* to find duplicate records in _the same_ database.\n",
    "\n",
    "<div style=\"text-align: right\">*De-duplication can sometimes involve matching more than 2 records within a database.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Most commonly, each record refers to a real-live person* (shown below, in case you forgot).\n",
    "<div style=\"text-align: right\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/6/68/Akha_cropped_hires.JPG\" alt=\"Akha cropped hires.JPG\" width=\"200\"></a><br><a href=\"https://en.wikipedia.org/wiki/User:Weltenbummler84\" class=\"extiw\" title=\"en:User:Weltenbummler84\">Image source</a></div>\n",
    "\n",
    "- Customers in a business database\n",
    "- Constituents in a government database\n",
    "- Patients in a hospital database\n",
    "<div style=\"text-align: right\">*Sometimes the entity to be matched is a business, or some other object.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/rl_pipeline_figure.png\" alt=\"RL pipeline figure\" width=\"456\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"pre\"></a>\n",
    "## Pre-processing\n",
    "\n",
    "<img src=\"assets/record_examples.png\" alt=\"Example records\" width=\"700\">\n",
    "\n",
    "Records from different databases often vary wildly in their formatting conventions.\n",
    "- As a result, it falls to use to ensure that the data we want to compare has been properly cleaned and standardized.\n",
    "- Any inconsistencies _must_ be resolved for successful linkage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the potential problems that may need to be addressed during pre-processing are too numerous to list -- we can refine the process into three major steps:\n",
    "1. Removing undesired characters/words\n",
    "    - Non-alphanumeric characters\n",
    "    - In some cases, removing irrelevant words (_stop words_) is useful.\n",
    "2. Standardize abbreviations and correct typos\n",
    "    - Use hash mapping to reduce the variation of equivalent values.\n",
    "3. Parsing input to create new variables (feature engineering)\n",
    "    - As we'll see, parsing our raw data into it's component elements allows us to model each of them individually, often resulting in a better performing model _and_ a greater ability to make inferences about which variables are most important during classification.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> Regardless of the specific pre-processing steps that you perform - <b>It is important to not over-write the original, raw data!</b>\n",
    "> - Otherwise, there is no guarantee that it can be recovered after being transformed.\n",
    "> - Later, different pre-processing may be desired.\n",
    "> Ideally, new copies of the data are created after each major transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%% Names?\n",
    "% - First, middle, family name is an Anglo-Saxon convention.\n",
    "% - How they change, or stay the same, depends on your culture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%% FILL OUT\n",
    "\n",
    "- Handling missing values\n",
    "- Handling outliers\n",
    "---\n",
    "- Filtering Characters/Tokens\n",
    "- Standardization\n",
    "    - Phonetic encoding\n",
    "        - Used to convert words into the way they are spoken, rather than the way they are spelled, since the latter can be more culturally-specific.\n",
    "        - Example: Soundex\n",
    "- Segmentation\n",
    "    - Rule-based\n",
    "    - Statistical (HMM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ideally, after pre-processing, those same records would look something like this below.\n",
    "\n",
    "<img src=\"assets/record_clean.png\" alt=\"Example records\" width=\"800\">\n",
    "\n",
    "- Our data now contains all attributes from both databases.\n",
    "- Content has been standardized.\n",
    "- Contradicting fields have been corrected\n",
    "- Abbreviations have been expanded\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"blocking\"></a>\n",
    "## Indexing (blocking)\n",
    "Now, we are ready to compare our records to look for a match.\n",
    "- But, if we are dealing with typical databases containing, say, a million or more records -- clearly we are not capable of comparing one trillion record pairs in a reasonable* time span.\n",
    "\n",
    "<div style=\"text-align: right\">*Ideally, we're talking minutes to hours, not days or weeks.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Like any good algorithm designer, though, we can start to think about where we can save ourselves from doing work.\n",
    "- The vast majority of record comparisons will be non-matches.\n",
    "- Especially so for records that are dis-similar along particular dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> For example, while matching record pairs may sometimes contain different phone numbers, they will almost never contain different genders. \n",
    "> - As a result, we can reduce the complexity of our algorithm substantially by simply comparing only records matching on gender.\n",
    ">\n",
    "> <img src=\"assets/blocking.png\" alt=\"Blocking example\" width=\"800\">\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<b><i>Blocking</i></b>, is a similar approach to indexing, which relies on a small number of such features to reduce the number of comparisons.\n",
    "- 'zip code' and 'phonetically-encoded surname' are two such examples.\n",
    "- For greater improvements in performance, it is common to block using <i>multiple</i> variables, in succession."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> <b>Warning!</b>: This approach does, however, sometimes miss certain matches that may, for example, contain a typo in one of the <i>blocking keys</i>.\n",
    "> - In the example above, the record would not have any chance of being matched in the event that gender changed or was entered incorrectly.\n",
    "> - This highlights the need for careful selection of blocking criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%% FILL OUT\n",
    "\n",
    "- Defining blocking keys\n",
    "    - Data quality/consistency\n",
    "    - Number vs. size of blocks\n",
    "    - Blocking keys can be optimized just like any other hyper-parameter.\n",
    "- Blocking is also an opportunity to leverage parallel processing approaches to decrease processing time, when that is applicable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"classification\"></a>\n",
    "## Comparison and classification\n",
    "\n",
    "Next, the similarity between our candidate pairs is calculated by comparing several record attributes.\n",
    "- This can range from simple numeric comparisons, like the difference between ages of each record, to more complex comparison functions, like 'fuzzy' string matching. \n",
    "- It also a good idea to include cross comparisons. \n",
    "    - For example, in certain cultures, first and last name are sometimes used in the reverse order. \n",
    "    - So, including a comparison of first name with last name can catch instances such as these.\n",
    "- A few examples of such comparisons are shown below.\n",
    "\n",
    "<img src=\"assets/record_comparison.png\" alt=\"Record comparison\" width=\"600\">\n",
    "\n",
    "The result is a <b>comparison vector</b> for each pair.\n",
    "- We calculated similarity using approximate comparisons for strings, edit distance for numbers, and equivalence for Booleans.\n",
    "- This <i>feature vector</i> is what we use for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%% Traditional record linkage entails using a probabilistic approach equivalent to a Naive Bayes classifier.\n",
    "% - The advantages of this approach, and perhaps the reason for its overwhelming popularity, are..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Using our comparison vector, we can no classify each record pair as either a 'match' or 'non-match'.\n",
    "- Given that this operation is performed on each record pair, <i>independently</i> of all other pairs, a given record may classify as a match for more than one record.\n",
    "\n",
    "%%% Put munkres here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"evaluation\"></a>\n",
    "## Evaluation\n",
    "Of course, in order to evaluate our algorithm, we would prefer to have access to labeled data that can be used for validation.\n",
    "- This would contain the true match status of all possible matches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<b>Unfortunately</b>, obtaining ground-truth data is very often not possible and so other solutions must be applied.\n",
    "\n",
    "%%% Discuss unsupervised approaches here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In the event we <i>do</i> have labeled data, we must still contend with a formidable class imbalance, between matches and non-matches.\n",
    "- As a result, appropriate classification metrics must be applied.\n",
    "    - Accuracy, for example, can grow very high by classifying everything as 'non-match'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this talk, we'll focus on classifying record pairs as either a 'match' or 'non-match'.\n",
    "- However, a third classification can sometimes be useful -- 'possible match'.\n",
    "- These records can then undergo clerical review, and the classified records can then be added to the training data for your model, thus improving your classifier.\n",
    "- This is very often not feasible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"demo\"></a>\n",
    "# Demo\n",
    "\n",
    "For this demo, we'll use [`recordlinkage`](https://recordlinkage.readthedocs.io/en/latest/about.html), a very popular and well-maintained Record Linkage toolkit for Python.\n",
    "- %%DESCRIBE DATA%%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"comparing\"></a>\n",
    "## Comparing the performance of classifiers\n",
    "\n",
    "Inspired by:\n",
    "https://recordlinkage.readthedocs.io/en/latest/notebooks/classifiers.html\n",
    "\n",
    "https://recordlinkage.readthedocs.io/en/latest/notebooks/link_two_dataframes.html\n",
    "\n",
    "https://recordlinkage.readthedocs.io/en/latest/ref-classifiers.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import recordlinkage as rl\n",
    "from recordlinkage.datasets import load_febrl4\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# load demo data (with true labels)\n",
    "dfA, dfB, true_links = load_febrl4(return_links=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>street_number</th>\n",
       "      <th>address_1</th>\n",
       "      <th>address_2</th>\n",
       "      <th>suburb</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>soc_sec_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rec-3110-org</th>\n",
       "      <td>michael</td>\n",
       "      <td>morden</td>\n",
       "      <td>67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>marjories corner</td>\n",
       "      <td>frankston</td>\n",
       "      <td>4123</td>\n",
       "      <td>qld</td>\n",
       "      <td>19091122</td>\n",
       "      <td>2399236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-1552-org</th>\n",
       "      <td>daniel</td>\n",
       "      <td>callahan</td>\n",
       "      <td>119</td>\n",
       "      <td>halifax close</td>\n",
       "      <td>medical centre</td>\n",
       "      <td>smythesdale</td>\n",
       "      <td>2400</td>\n",
       "      <td>nsw</td>\n",
       "      <td>19530309</td>\n",
       "      <td>3925704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-3984-org</th>\n",
       "      <td>david</td>\n",
       "      <td>sette</td>\n",
       "      <td>8</td>\n",
       "      <td>spring range road</td>\n",
       "      <td>jessiefield</td>\n",
       "      <td>villawood</td>\n",
       "      <td>2213</td>\n",
       "      <td>wa</td>\n",
       "      <td>19950603</td>\n",
       "      <td>9471099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             given_name   surname street_number          address_1  \\\n",
       "rec_id                                                               \n",
       "rec-3110-org    michael    morden            67                NaN   \n",
       "rec-1552-org     daniel  callahan           119      halifax close   \n",
       "rec-3984-org      david     sette             8  spring range road   \n",
       "\n",
       "                     address_2       suburb postcode state date_of_birth  \\\n",
       "rec_id                                                                     \n",
       "rec-3110-org  marjories corner    frankston     4123   qld      19091122   \n",
       "rec-1552-org    medical centre  smythesdale     2400   nsw      19530309   \n",
       "rec-3984-org       jessiefield    villawood     2213    wa      19950603   \n",
       "\n",
       "             soc_sec_id  \n",
       "rec_id                   \n",
       "rec-3110-org    2399236  \n",
       "rec-1552-org    3925704  \n",
       "rec-3984-org    9471099  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfA.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>street_number</th>\n",
       "      <th>address_1</th>\n",
       "      <th>address_2</th>\n",
       "      <th>suburb</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>soc_sec_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rec-1414-dup-0</th>\n",
       "      <td>zali</td>\n",
       "      <td>eglinton</td>\n",
       "      <td>14</td>\n",
       "      <td>adcock place</td>\n",
       "      <td>trewilga</td>\n",
       "      <td>woodlajnds</td>\n",
       "      <td>2122</td>\n",
       "      <td>qld</td>\n",
       "      <td>19300914</td>\n",
       "      <td>7126898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-4802-dup-0</th>\n",
       "      <td>laim</td>\n",
       "      <td>wilkins</td>\n",
       "      <td>2</td>\n",
       "      <td>hansen circuit</td>\n",
       "      <td>foresdtale</td>\n",
       "      <td>sadleir</td>\n",
       "      <td>5018</td>\n",
       "      <td>sa</td>\n",
       "      <td>19530304</td>\n",
       "      <td>6164019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-1963-dup-0</th>\n",
       "      <td>rebekah</td>\n",
       "      <td>green</td>\n",
       "      <td>14</td>\n",
       "      <td>laker crescent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>whittinhgam</td>\n",
       "      <td>2166</td>\n",
       "      <td>wa</td>\n",
       "      <td>19920111</td>\n",
       "      <td>4383145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               given_name   surname street_number       address_1   address_2  \\\n",
       "rec_id                                                                          \n",
       "rec-1414-dup-0       zali  eglinton            14    adcock place    trewilga   \n",
       "rec-4802-dup-0       laim   wilkins             2  hansen circuit  foresdtale   \n",
       "rec-1963-dup-0    rebekah     green            14  laker crescent         NaN   \n",
       "\n",
       "                     suburb postcode state date_of_birth soc_sec_id  \n",
       "rec_id                                                               \n",
       "rec-1414-dup-0   woodlajnds     2122   qld      19300914    7126898  \n",
       "rec-4802-dup-0      sadleir     5018    sa      19530304    6164019  \n",
       "rec-1963-dup-0  whittinhgam     2166    wa      19920111    4383145  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfB.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3241\n"
     ]
    }
   ],
   "source": [
    "# indexing step\n",
    "indexer = rl.Index()\n",
    "indexer.block('given_name')\n",
    "candidate_links = indexer.index(dfA, dfB)\n",
    "\n",
    "# comparison step\n",
    "compare_cl = rl.Compare()\n",
    "\n",
    "compare_cl.exact('given_name', 'given_name', label='given_name')\n",
    "compare_cl.string('surname', 'surname', method='jarowinkler', threshold=0.85, label='surname')\n",
    "compare_cl.exact('date_of_birth', 'date_of_birth', label='date_of_birth')\n",
    "compare_cl.exact('suburb', 'suburb', label='suburb')\n",
    "compare_cl.exact('state', 'state', label='state')\n",
    "compare_cl.string('address_1', 'address_1', threshold=0.85, label='address_1')\n",
    "\n",
    "# generate feature array\n",
    "features = compare_cl.compute(candidate_links, dfA, dfB)\n",
    "\n",
    "# classification step: simple threshold \n",
    "matches = features[features.sum(axis=1) > 3]\n",
    "print(len(matches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"supervised\"></a>\n",
    "### Supervised\n",
    "\n",
    "https://recordlinkage.readthedocs.io/en/latest/notebooks/classifiers.html#Supervised-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57936, 6)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2470,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_matches_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training and test set\n",
    "X_train, X_test = train_test_split(features, test_size=0.25)\n",
    "\n",
    "# Get the true pairs for each set\n",
    "y_train = train.index & true_links\n",
    "y_test = test.index & true_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept:  -7.005760071500094\n",
      "Coefficients:  [1.33285530e-04 2.49832701e+00 2.09972768e+00 9.64041143e-01\n",
      " 1.73354964e+00 1.87220448e+00]\n"
     ]
    }
   ],
   "source": [
    "# train logistic regression classifier\n",
    "logreg = rl.LogisticRegressionClassifier()\n",
    "\n",
    "# train classifier\n",
    "logreg.fit(X_train, y_train)\n",
    "print (\"Intercept: \", logreg.intercept)\n",
    "print (\"Coefficients: \", logreg.coefficients)\n",
    "\n",
    "# predict match status for record pairs\n",
    "predictions_logreg = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 170,  647],\n",
       "       [ 472, -472]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rl.confusion_matrix(y_test, predictions_logreg, len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22757887274016303"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The F-score for this prediction is\n",
    "rl.fscore(true_links, predictions_logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 200,  617],\n",
       "       [ 557, -557]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train Naive Bayes classifier\n",
    "nb = rl.NaiveBayesClassifier(binarize=0.3)\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# predict match status for record pairs\n",
    "predictions_nb = nb.predict(X_test)\n",
    "\n",
    "rl.confusion_matrix(y_test, predictions_nb, len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26298419315615773"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rl.fscore(true_links, predictions_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 184,  633],\n",
       "       [ 504, -504]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train svm classifier\n",
    "svm = rl.SVMClassifier()\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# predict match status for record pairs\n",
    "predictions_svm = svm.predict(X_test)\n",
    "\n",
    "rl.confusion_matrix(y_test, predictions_svm, len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2419127988748242"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rl.fscore(true_links, predictions_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"unsupervised\"></a>\n",
    "### Unsupervised\n",
    "\n",
    "https://recordlinkage.readthedocs.io/en/latest/notebooks/classifiers.html#Unsupervised-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 200,  617],\n",
       "       [ 557, -557]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train kmeans classifier\n",
    "kmeans = rl.KMeansClassifier()\n",
    "kmeans.fit(X_train)\n",
    "\n",
    "# predict match status for record pairs\n",
    "predictions_kmeans = kmeans.predict(X_test)\n",
    "\n",
    "rl.confusion_matrix(y_test, predictions_kmeans, len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26298419315615773"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rl.fscore(true_links, predictions_kmeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expectation/Conditional Maximization Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 200,  617],\n",
       "       [ 563, -563]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train ecm classifier\n",
    "ecm = rl.ECMClassifier(binarize=0.8)\n",
    "ecm.fit(X_train)\n",
    "\n",
    "# predict match status for record pairs\n",
    "predictions_ecm = ecm.predict(X_test)\n",
    "\n",
    "rl.confusion_matrix(y_test, predictions_ecm, len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26479264272080516"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rl.fscore(true_links, predictions_ecm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%% [CREATE MULTI-CLASS ROC CURVE TO FINISH 'ER OFF!!!!!]"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
